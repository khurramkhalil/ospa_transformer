{
  "data_dir": "./data",
  "output_dir": "experiments/large_scale/large_wmt16",
  "model_name": "",
  "max_seq_length": 128,
  "dataset_name": "wmt16",
  "language_pair": "de-en",
  "d_model": 768,
  "nhead": 12,
  "num_encoder_layers": 12,
  "num_decoder_layers": 12,
  "dim_feedforward": 3072,
  "dropout": 0.1,
  "enforce_mode": "regularize",
  "ortho_penalty_weight": 0.0005,
  "batch_size": 8,
  "learning_rate": 3e-05,
  "weight_decay": 0.01,
  "epochs": 3,
  "seed": 42,
  "num_workers": 0
}